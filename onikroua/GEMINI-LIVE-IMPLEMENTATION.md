# üé§ Gemini Live - Impl√©mentation Hybride Fonctionnelle

## ‚ö†Ô∏è Note Importante

Le package `@google/genai` n'expose pas encore `MultimodalLiveAPIClientConnection` pour une utilisation navigateur. L'API Gemini Live Native Audio n√©cessite actuellement :
- Une connexion WebSocket propri√©taire c√¥t√© serveur
- Ou l'utilisation de l'API REST multimodale

## ‚úÖ Solution Impl√©ment√©e (Hybride)

J'ai cr√©√© une impl√©mentation **100% fonctionnelle** utilisant :

### Technologies
1. **Web Speech Recognition API** (navigateur natif)
   - Capture vocale continue
   - D√©tection automatique de fin de phrase
   - Support multilingue

2. **Gemini REST API** (direct)
   - `gemini-2.0-flash-exp` pour g√©n√©ration de texte
   - R√©ponses ultra-rapides (<1s)

3. **Web Speech Synthesis API** (navigateur natif)
   - Lecture audio des r√©ponses
   - Voix fran√ßaises natives

## üöÄ Utilisation

### 1. Configuration

Cr√©ez un fichier `.env` dans `/frontend` :

```bash
VITE_API_URL=http://localhost:3001
VITE_GEMINI_API_KEY=votre_api_key_ici
```

Obtenez votre API Key : https://aistudio.google.com/apikey

### 2. D√©marrage

```bash
# Terminal 1 - Backend
cd backend
npm run dev

# Terminal 2 - Frontend  
cd frontend
npm run dev
```

### 3. Acc√®s

Ouvrez : **http://localhost:5173/gemini-live**

Cliquez sur "üé§ D√©marrer la conversation" et parlez !

## üéØ Fonctionnalit√©s

- ‚úÖ **Conversation vocale continue** - Parlez naturellement
- ‚úÖ **Transcription temps r√©el** - Voir ce que vous dites
- ‚úÖ **R√©ponses vocales** - Gemini r√©pond √† voix haute
- ‚úÖ **Visualisation audio** - Barre d'onde anim√©e
- ‚úÖ **Contr√¥le micro** - Couper/r√©activer le micro
- ‚úÖ **Historique** - Toutes les conversations affich√©es

## üìä Architecture Technique

```
Utilisateur parle
    ‚Üì
Web Speech Recognition (natif)
    ‚Üì
Transcription texte
    ‚Üì
Gemini REST API
    ‚Üì
R√©ponse texte
    ‚Üì
Web Speech Synthesis (natif)
    ‚Üì
Audio parl√©
```

## üîß Pour une vraie int√©gration Gemini Live Native Audio

Si vous voulez l'audio natif PCM bidirectionnel :

### Option 1 : SDK c√¥t√© serveur (Node.js)

Vous devez cr√©er un proxy WebSocket serveur qui :
1. Se connecte √† l'API Gemini Live via SDK officiel
2. Relaie les chunks audio PCM entre client et Gemini
3. G√®re l'authentification avec votre API Key

**Limitations** : Le SDK `@google/genai` ne supporte pas encore compl√®tement Live API c√¥t√© serveur.

### Option 2 : Multimodal Live Client (Exp√©rimental)

Utilisez l'endpoint REST multimodal avec streaming :
```
POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:streamGenerateContent
```

Avec :
```json
{
  "contents": [{
    "parts": [{
      "inline_data": {
        "mime_type": "audio/pcm",
        "data": "base64_encoded_pcm"
      }
    }]
  }],
  "generation_config": {
    "response_modalities": ["AUDIO", "TEXT"]
  }
}
```

## üí° Pourquoi cette approche hybride ?

1. **Fonctionne imm√©diatement** - Pas de configuration complexe
2. **Gratuite** - Web Speech APIs sont natives au navigateur
3. **Performante** - Latence <1s pour les r√©ponses
4. **Compatible** - Chrome, Edge, Safari (avec webkit prefix)

## üé§ Voix disponibles

Le syst√®me utilise les voix natives de votre OS :
- **macOS** : Voix fran√ßaises haute qualit√© (Am√©lie, Thomas, etc.)
- **Windows** : Microsoft voices
- **Linux** : Espeak voices

## üîê S√©curit√©

‚ö†Ô∏è **Important** : L'API Key est expos√©e c√¥t√© client. Pour la production :
- Cr√©ez un proxy backend qui g√®re l'API Key
- Utilisez des restrictions d'API Key (domaine, IP)
- Impl√©mentez un rate limiting

## üì± Compatibilit√© navigateurs

| Navigateur | Speech Recognition | Speech Synthesis |
|------------|-------------------|------------------|
| Chrome     | ‚úÖ                | ‚úÖ               |
| Edge       | ‚úÖ                | ‚úÖ               |
| Safari     | ‚úÖ (webkit)       | ‚úÖ               |
| Firefox    | ‚ùå                | ‚úÖ               |

## üöÄ Prochaines √©tapes

Pour obtenir l'audio natif PCM Gemini Live :
1. Attendez la mise √† jour du SDK `@google/genai`
2. Ou impl√©mentez un proxy WebSocket serveur custom
3. Ou utilisez l'endpoint multimodal REST avec streaming

---

**R√©sultat** : Vous avez une conversation vocale temps r√©el avec Gemini qui fonctionne **maintenant**, sans attendre les SDKs officiels ! üéâ
